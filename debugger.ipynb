{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n",
      "I0301 12:59:50.624491 139623539795776 file_utils.py:38] PyTorch version 1.4.0 available.\n",
      "I0301 12:59:51.843101 139623539795776 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I0301 12:59:52.166258 139623539795776 modeling_bert.py:244] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_HOME\"] = '/disks/sdb/torch_home'\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext snoop\n",
    "\n",
    "\n",
    "import itertools\n",
    "import pandas\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "# from allennlp.data.token_indexers.bert_tokenizers import PretrainedBertIndexer\n",
    "\n",
    "from awesome_glue.task import Task\n",
    "from awesome_glue.utils import AttackMetric\n",
    "from awesome_glue.config import Config\n",
    "\n",
    "from luna import ram_write, chunks\n",
    "from allennlpx import allenutil\n",
    "\n",
    "from luna import ram_read\n",
    "\n",
    "from allennlpx.interpret.attackers.embedding_searcher import EmbeddingSearcher\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import List\n",
    "\n",
    "# pylint: disable=protected-access\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "from itertools import product\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from allennlp.common.util import JsonDict, sanitize\n",
    "from allennlp.data.fields import TextField\n",
    "from allennlp.data.token_indexers import (ELMoTokenCharactersIndexer,\n",
    "                                          TokenCharactersIndexer)\n",
    "from allennlp.data.tokenizers import SpacyTokenizer, Token\n",
    "from allennlp.modules.text_field_embedders.text_field_embedder import \\\n",
    "    TextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "\n",
    "from allennlpx import allenutil\n",
    "from allennlpx.interpret.attackers.attacker import (DEFAULT_IGNORE_TOKENS,\n",
    "                                                    Attacker)\n",
    "from allennlpx.interpret.attackers.embedding_searcher import EmbeddingSearcher\n",
    "from allennlpx.interpret.attackers.policies import (CandidatePolicy,\n",
    "                                                    EmbeddingPolicy,\n",
    "                                                    SynonymPolicy)\n",
    "from allennlpx.interpret.attackers.synonym_searcher import SynonymSearcher\n",
    "from luna import cast_list, lazy_property, time_record\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-spacy exists\n",
      "*** load SST-spacy from cache cost 2.75 seconds\n",
      "cache for 2f2a46e51336b27a7262689b00016955 exists\n",
      "*** load 2f2a46e51336b27a7262689b00016955 from cache cost 0.0351 seconds\n",
      "Restore model from checkpoint saved/models/SST-lstm-glove@0.ckpt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Basic Args:\n",
       "\t--task_id=SST\n",
       "\t--finetunable=True\n",
       "\t--arch=lstm\n",
       "\t--pretrain=glove\n",
       "\t--_model_name=SST-lstm-glove\n",
       "\t--mode=attack\n",
       "\t--adv_data=nogit/SST-bert.adv.tsv\n",
       "\t--aug_data=\n",
       "\t--attack_vectors=glove\n",
       "\t--attack_data_split=dev\n",
       "\t--attack_size=100\n",
       "\t--attack_gen_aug=False\n",
       "\t--attack_gen_adv=False\n",
       "\t--alchemist=False\n",
       "\t--seed=2\n",
       "Deduced Args:\n",
       "\t--model_name=SST-lstm-glove\n",
       "\t--tokenizer=spacy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "# config.finetunable=True\n",
    "task = Task(config) # type: Task\n",
    "task.from_pretrained()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlpx.interpret.attackers.pwws import PWWS\n",
    "attacker = PWWS(task.predictor)\n",
    "attacker.initialize()\n",
    "sent = allenutil.as_sentence(task.dev_data[15])\n",
    "print(sent)\n",
    "print(task.predictor.predict(sent), '\\n')\n",
    "result = attacker.attack_from_json({\"sent\": sent},\n",
    "                                   field_to_change=\"sent\",\n",
    "#                                    ignore_tokens=forbidden_words,\n",
    "#                                    forbidden_tokens=forbidden_words,\n",
    "                                   max_change_num_or_ratio=0.25,\n",
    "                                   measure='euc',\n",
    "                                   topk=300,\n",
    "#                                                    search_num=256\n",
    "                                  )\n",
    "print(result)\n",
    "print(allenutil.as_sentence(result['raw']))\n",
    "print(allenutil.as_sentence(result['adv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# List available models\n",
    "torch.hub.list('pytorch/fairseq')  # [..., 'transformer_lm.wmt19.en', ...]\n",
    "\n",
    "# Load an English LM trained on WMT'19 News Crawl data\n",
    "en_lm = torch.hub.load('pytorch/fairseq', 'transformer_lm.wmt19.en', tokenizer='moses', bpe='fastbpe')\n",
    "en_lm.eval()  # disable dropout\n",
    "\n",
    "# Move model to GPU\n",
    "en_lm.cuda(1)\n",
    "\n",
    "# Sample from the language model\n",
    "en_lm.sample('Barack Obama', beam=1, sampling=True, sampling_topk=10, temperature=0.8)\n",
    "# \"Barack Obama is coming to Sydney and New Zealand (...)\"\n",
    "\n",
    "# Compute perplexity for a sequence\n",
    "en_lm.score('Barack Obama is coming to Sydney and New Zealand')['positional_scores'].mean().neg().exp()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(101.9296, device='cuda:1'),\n",
       " tensor(101.9296, device='cuda:1'),\n",
       " tensor(101.9296, device='cuda:1'),\n",
       " tensor(101.9296, device='cuda:1')]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = ['Barack Obama is coming to Beijing'] * 4\n",
    "results = en_lm.score(lst)\n",
    "ppls = [ele['positional_scores'].mean().neg().exp() for ele in results]\n",
    "ppls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(en_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /disks/sdb/torch_home/hub/pytorch_fairseq_master\n",
      "I0301 13:09:20.997089 139623539795776 file_utils.py:71] loading archive file https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.en.tar.bz2 from cache at /disks/sdb/torch_home/pytorch_fairseq/0cabe4a3e5ef7de13b205be3ab7feaf000768c332991cab28503a5464cbd5133.1194dafe66fa251b0e81fb532efac27216c501bfb0573c5d7e77e04dd6d88b15\n",
      "I0301 13:09:23.297399 139623539795776 language_modeling.py:116] dictionary: 42022 types\n",
      "I0301 13:09:32.551391 139623539795776 fairseq_model.py:198] Namespace(activation_fn='relu', adaptive_input=False, adaptive_input_cutoff=None, adaptive_input_factor=4, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_softmax_factor=4, add_bos_token=False, arch='transformer_lm_gbw', attention_dropout=0.1, bpe='fastbpe', bpe_codes='/disks/sdb/torch_home/pytorch_fairseq/0cabe4a3e5ef7de13b205be3ab7feaf000768c332991cab28503a5464cbd5133.1194dafe66fa251b0e81fb532efac27216c501bfb0573c5d7e77e04dd6d88b15/bpecodes', bucket_cap_mb=25, char_embedder_highway_layers=2, character_embedding_dim=4, character_embeddings=False, character_filters='[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', clip_norm=0.1, cpu=False, criterion='cross_entropy', curriculum=0, data='/disks/sdb/torch_home/pytorch_fairseq/0cabe4a3e5ef7de13b205be3ab7feaf000768c332991cab28503a5464cbd5133.1194dafe66fa251b0e81fb532efac27216c501bfb0573c5d7e77e04dd6d88b15', ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1536, decoder_ffn_embed_dim=6144, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=20, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair1082:12597', distributed_port=12597, distributed_rank=0, distributed_world_size=128, dropout=0.1, fix_batches_to_gpus=False, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, keep_interval_updates=1, keep_last_epochs=-1, layernorm_embedding=False, lazy_load=False, log_format='json', log_interval=1000, lr=[5e-05], lr_period_updates=959000.0, lr_scheduler='cosine', lr_shrink=0.6, max_epoch=0, max_lr=1.0, max_sentences=None, max_sentences_valid=None, max_source_positions=512, max_target_positions=512, max_tokens=2048, max_update=1000000, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, moses_no_dash_splits=False, moses_no_escape=False, no_decoder_final_norm=True, no_epoch_checkpoints=True, no_progress_bar=False, no_save=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=0, optimizer='nag', optimizer_overrides='{}', output_dictionary_size=-1, past_target=False, raw_text=False, relu_dropout=0.1, required_batch_size_multiple=8, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sample_break_mode='eos', save_dir='/checkpoint/nng/lm/wmt/20190404/lm_newscrawl_en.mxup1000000.mlr1.0.tmult2.per959000.csn.lrs0.6.wrm16000.int1e-07.nag.lr5e-05.clp0.1.lyr20.hd16.drp0.1.ffn6144.at_d0.1.rl_d0.1.i1024.m1536.o1024.mxtk2048.tps512.seed1.bm=eos.ngpu128', save_interval=1, save_interval_updates=959000, seed=1, self_target=False, sentence_avg=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, t_mult=2.0, task='language_modeling', tensorboard_logdir='/checkpoint/nng/tensorboard_logs/2019-04-04/lm_newscrawl_en.mxup1000000.mlr1.0.tmult2.per959000.csn.lrs0.6.wrm16000.int1e-07.nag.lr5e-05.clp0.1.lyr20.hd16.drp0.1.ffn6144.at_d0.1.rl_d0.1.i1024.m1536.o1024.mxtk2048.tps512.seed1.bm=eos.ngpu128', threshold_loss_scale=None, tie_adaptive_proj=False, tie_adaptive_weights=False, tokenizer='moses', tokens_per_sample=512, train_subset='train', truncate_sequence=False, update_freq=[1], user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=16000, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .\n",
      "the acting , costumes , music , cinematography and noise are all impressive given the project one bleak locales .\n",
      "{'logits': [0.13473094999790192, -0.17793287336826324], 'probs': [0.5775353312492371, 0.42246463894844055]}\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "kwargs = { \n",
    "#                 \"ignore_tokens\": [\"is\"],\n",
    "#                 \"forbidden_tokens\": [\"is\"],\n",
    "                \"max_change_num_or_ratio\": 0.25\n",
    "            }\n",
    "attacker = Genetic(task.predictor, **kwargs)\n",
    "attacker.initialize()\n",
    "attacker.perturb(\"the dog is lovely\".split(\" \"),\n",
    "                                \"the cat is lovely\".split(\" \"),)\n",
    "result = attacker.attack_from_json({'sent': allenutil.as_sentence(task.dev_data[2])},\n",
    "                         field_to_change='sent')\n",
    "if result['success'] == 1:\n",
    "    print(allenutil.as_sentence(result['raw']))\n",
    "    print(allenutil.as_sentence(result['adv']))\n",
    "    print(result['outputs'])\n",
    "    print(result['success'])\n",
    "    print(result['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales .\n",
      "the acting , costumes , song , cinematography and noise are all impressive given the production 's desolate locales .\n",
      "{'logits': [0.0036784783005714417, -0.028392136096954346], 'probs': [0.5080170035362244, 0.491983026266098]}\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "result = attacker.attack_from_json({'sent': allenutil.as_sentence(task.dev_data[2])},\n",
    "                         field_to_change='sent')\n",
    "if result['success'] == 1:\n",
    "    print(allenutil.as_sentence(result['raw']))\n",
    "    print(allenutil.as_sentence(result['adv']))\n",
    "    print(result['outputs'])\n",
    "    print(result['success'])\n",
    "    print(result['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m': 3}\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "        \n",
    "class B(A):\n",
    "    def __init__(self, c, *, d, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        print(kwargs)\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "        \n",
    "b = B(c=1, d=2, m=3)\n",
    "print(b.c)\n",
    "print(b.m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
