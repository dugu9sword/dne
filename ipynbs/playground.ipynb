{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/disks/sdb/zhouyi/frequency\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /disks/sdb/zhouyi/frequency\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = \"/disks/sdb/torch_home\"\n",
    "\n",
    "from awesome_glue.task import *\n",
    "from awesome_glue.config import Config\n",
    "from collections import defaultdict\n",
    "from tabulate import tabulate\n",
    "from allennlp.data import Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-bert.data exists\n",
      "*** load SST-bert.data from cache cost 4.22 seconds\n",
      "cache for SST-counter-for-bert.vec exists\n",
      "*** load SST-counter-for-bert.vec from cache cost 0.027 seconds\n",
      "Load model from saved/models/SST-dbert-5.0/best.th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Basic Args:\n",
       "\t--task_id=SST\n",
       "\t--embed=d\n",
       "\t--arch=bert\n",
       "\t--pretrain=glove\n",
       "\t--_model_name=\n",
       "\t--mode=train\n",
       "\t--dir_temp=5.0\n",
       "\t--gnn_type=mean\n",
       "\t--gnn_hop=1\n",
       "\t--aug_data=\n",
       "\t--adv_iter=0\n",
       "\t--adv_policy=hot\n",
       "\t--adv_replace_num=5\n",
       "\t--adv_constraint=True\n",
       "\t--pred_ensemble=1\n",
       "\t--pred_transform=\n",
       "\t--pred_transform_args=\n",
       "\t--attack_method=pwws\n",
       "\t--attack_vectors=counter\n",
       "\t--attack_data_split=dev\n",
       "\t--attack_size=200\n",
       "\t--attack_gen_adv=False\n",
       "\t--adv_data=nogit/AGNEWS-lstm.hotflip.adv.tsv\n",
       "\t--alchemist=False\n",
       "\t--seed=2\n",
       "\t--cuda=3\n",
       "Deduced Args:\n",
       "\t--model_name=SST-dbert-5.0\n",
       "\t--tokenizer=bert"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(2)\n",
    "\n",
    "config = Config()\n",
    "\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-spacy.data exists\n",
      "*** load SST-spacy.data from cache cost 3.53 seconds\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"SST\", \"spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data['data'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 ms ± 3.21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit data['reader'].transform_instances(lambda x: x, list(data['data'][2])[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 ms ± 682 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [deepcopy(ele) for ele in list(data['data'][2])[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 ms ± 51.7 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pool.copy(list(data['data'][2])[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-704cf87ae359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "instance = Instance(fields=None)\n",
    "instance.fields['d'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 08:32:55.542394 139855135606592 embedding.py:383] Reading pretrained embeddings from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-counter does not exist\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaf7bd264944639bed7e4ede7efbc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 08:32:56.684500 139855135606592 embedding.py:421] Initializing pre-trained embedding layer\n",
      "I0401 08:32:56.818040 139855135606592 embedding.py:439] Pretrained embeddings were found for 11096 out of 12734 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** create SST-counter and save to cache cost 1.3 seconds\n"
     ]
    }
   ],
   "source": [
    "weight = embed_util.read_weight(data['vocab'], 'counter', 'SST-counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_searcher = EmbeddingSearcher(weight, data['vocab'].get_token_index, data['vocab'].get_token_from_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Statistics of parameters and 2-norm ***\n",
      "[INFO] Param Mean -0.0006 Std 0.0539 Max 0.5341\n",
      "[INFO] Norm Mean 0.8714 Std 0.3348 Max 1.0000\n",
      "*** Statistics of distances in a N-nearest neighbourhood ***\n",
      "    N    mean    std\n",
      "-----  ------  -----\n",
      "    5    0.32   0.18\n",
      "   10    0.39   0.18\n",
      "   20    0.46   0.17\n",
      "   50    0.55   0.16\n",
      "  100    0.62   0.14\n",
      "  200    0.68   0.12\n",
      "  500    0.74   0.10\n",
      "10000    0.94   0.07\n",
      "20000    0.97   0.08\n"
     ]
    }
   ],
   "source": [
    "embed_searcher.show_embedding_info('cos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(padding_token='[PAD]', oov_token='[UNK]')\n",
    "from allennlp.data.token_indexers import PretrainedTransformerIndexer\n",
    "PretrainedTransformerIndexer(\"bert-base-uncased\", \"tokens\")._add_encoding_to_vocabulary_if_needed(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_vocab_size(\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../saved/models/AGNEWS-lstm/model_state_epoch_5.th'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.training.checkpointer import Checkpointer\n",
    "ckpter = Checkpointer('../saved/models/AGNEWS-lstm')\n",
    "ckpter.find_latest_checkpoint()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 07:42:19.564311 140387497060160 embedding.py:383] Reading pretrained embeddings from file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a757e442e3c54067a1d44e613462a563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 07:42:21.463958 140387497060160 embedding.py:421] Initializing pre-trained embedding layer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 07:42:21.773792 140387497060160 embedding.py:439] Pretrained embeddings were found for 20994 out of 30522 tokens\n"
     ]
    }
   ],
   "source": [
    "w = _read_pretrained_embeddings_file(\n",
    "            WORD2VECS['counter'],\n",
    "            embedding_dim=EMBED_DIM['counter'],\n",
    "            vocab=task.vocab,\n",
    "            namespace=\"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20994, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[:, 0].nonzero().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.model.bert_model.transformer_model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.model.bert_model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent1': 'A person on a horse jumps over a broken down airplane .',\n",
       " 'sent2': 'A person is outdoors , on a horse .'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField\n",
    "from allennlpx.allenutil import as_sentence\n",
    "allenutil.as_sentence(task.train_data[0].fields['sent1'])\n",
    "def as_json(instance: Instance):\n",
    "    ret = {}\n",
    "    for k, v in instance.items():\n",
    "        if isinstance(v, TextField):\n",
    "            ret[k] = as_sentence(v)\n",
    "    return ret\n",
    "as_json(task.train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'to',\n",
       " \"'s\",\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'it',\n",
       " 'as',\n",
       " 'with',\n",
       " 'an',\n",
       " 'film',\n",
       " 'for',\n",
       " 'its',\n",
       " 'movie',\n",
       " 'this',\n",
       " '`',\n",
       " 'you',\n",
       " 'be',\n",
       " 'but',\n",
       " 'on',\n",
       " 'by',\n",
       " 'more',\n",
       " 'one',\n",
       " '--',\n",
       " 'at',\n",
       " 'than',\n",
       " 'has',\n",
       " 'from',\n",
       " 'about',\n",
       " 'his',\n",
       " 'are',\n",
       " 'so',\n",
       " 'all',\n",
       " 'or',\n",
       " 'have',\n",
       " 'most',\n",
       " 'out',\n",
       " 'story',\n",
       " 'too',\n",
       " 'into',\n",
       " 'up',\n",
       " 'who',\n",
       " 'characters',\n",
       " 'i',\n",
       " 'comedy',\n",
       " 'if',\n",
       " 'just']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forbidden_words = DEFAULT_IGNORE_TOKENS\n",
    "forbidden_words.extend([\n",
    "    line.rstrip('\\n') for line in open(TASK_SPECS['SST']['banned_words'])\n",
    "])\n",
    "# forbidden_words += stopwords.words(\"english\")\n",
    "high_words = FreqUtil.topk_frequency(task.vocab, 50, 'most', forbidden_words)\n",
    "high_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-spacy.data exists\n",
      "*** load SST-spacy.data from cache cost 4.23 seconds\n",
      "cache for SST-glove.vec exists\n",
      "*** load SST-glove.vec from cache cost 0.0137 seconds\n",
      "Load model from saved/models/SST-lstm/best.th\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.task_id = 'SST'\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config\n",
    "\n",
    "\n",
    "# values = list(task.vocab.get_index_to_token_vocabulary().values())\n",
    "values = high_words\n",
    "results = defaultdict(lambda: [], {})\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "for group in lazy_groups_of(values, 1024):\n",
    "    result = task.predictor.predict_batch_json([{\"sent\": ele} for ele in group])\n",
    "    for i in range(len(result[0]['probs'])):\n",
    "        results[i].extend([ele['probs'][i] for ele in result])\n",
    "pairs = defaultdict(lambda: [], {})\n",
    "for i in range(len(results)):\n",
    "    pairs[i] = sorted(zip(values, results[i]), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-spacy.data exists\n",
      "*** load SST-spacy.data from cache cost 3.22 seconds\n",
      "cache for SST-glove.vec exists\n",
      "*** load SST-glove.vec from cache cost 0.0091 seconds\n",
      "Load model from saved/models/SST-glstm/best.th\n"
     ]
    }
   ],
   "source": [
    "config._model_name = 'SST-glstm'\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config\n",
    "\n",
    "# values = list(task.vocab.get_index_to_token_vocabulary().values())\n",
    "values = high_words\n",
    "results = defaultdict(lambda: [], {})\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "for group in lazy_groups_of(values, 1024):\n",
    "    result = task.predictor.predict_batch_json([{\"sent\": ele} for ele in group])\n",
    "    for i in range(len(result[0]['probs'])):\n",
    "        results[i].extend([ele['probs'][i] for ele in result])\n",
    "pairs2 = defaultdict(lambda: [], {})\n",
    "for i in range(len(results)):\n",
    "    pairs2[i] = sorted(zip(values, results[i]), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], []]\n",
      "[[1], [1]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "x=[]\n",
    "xs = [x] * 2\n",
    "ys = [deepcopy(ele) for ele in xs]\n",
    "ys[0].append(1)\n",
    "print(ys)\n",
    "ys = deepcopy(xs)\n",
    "ys[0].append(1)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'goto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-02e505c50643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I am trapped, please rescue!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'goto'"
     ]
    }
   ],
   "source": [
    "from goto import goto, label\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        for k in range(9):\n",
    "            print(\"I am trapped, please rescue!\")\n",
    "            if k == 2:\n",
    "                goto .breakout # breaking out from a deeply nested loop\n",
    "label .breakout\n",
    "print(\"Freedom!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word          normal    adv\n",
      "----------  --------  -----\n",
      "too             0.96   0.95\n",
      "or              0.82   0.98\n",
      "if              0.76   0.86\n",
      "from            0.71   0.44\n",
      "than            0.66   0.98\n",
      "have            0.6    0.03\n",
      "out             0.58   0.9\n",
      "its             0.57   0.42\n",
      "on              0.56   0.38\n",
      "just            0.56   0.91\n",
      "`               0.54   0.4\n",
      "at              0.53   0.44\n",
      "as              0.53   0.32\n",
      "but             0.53   0.35\n",
      "by              0.51   0.46\n",
      "about           0.48   0.31\n",
      "of              0.47   0.49\n",
      "movie           0.47   0.38\n",
      "one             0.47   0.41\n",
      "that            0.47   0.48\n",
      "for             0.47   0.3\n",
      "a               0.46   0.98\n",
      "so              0.45   0.13\n",
      "be              0.45   0.3\n",
      "most            0.45   0.91\n",
      "the             0.44   0.47\n",
      "more            0.44   0.02\n",
      "into            0.43   0.44\n",
      "with            0.42   0.45\n",
      "in              0.42   0.39\n",
      "his             0.42   0.16\n",
      "it              0.42   0.5\n",
      "all             0.41   0.17\n",
      "story           0.4    0.02\n",
      "an              0.39   0.45\n",
      "to              0.39   0.34\n",
      "this            0.39   0.22\n",
      "who             0.36   0.4\n",
      "'s              0.35   0.27\n",
      "are             0.35   0.83\n",
      "--              0.35   0.51\n",
      "i               0.33   0.14\n",
      "up              0.33   0.14\n",
      "film            0.31   0.94\n",
      "and             0.28   0.99\n",
      "has             0.25   0.19\n",
      "is              0.23   0.03\n",
      "comedy          0.19   0.88\n",
      "characters      0.16   0.58\n",
      "you             0.07   0.01\n",
      "word          normal    adv\n",
      "----------  --------  -----\n",
      "you             0.93   0.99\n",
      "characters      0.84   0.42\n",
      "comedy          0.81   0.12\n",
      "is              0.77   0.97\n",
      "has             0.75   0.81\n",
      "and             0.72   0.01\n",
      "film            0.69   0.06\n",
      "up              0.67   0.86\n",
      "i               0.67   0.86\n",
      "--              0.65   0.49\n",
      "are             0.65   0.17\n",
      "'s              0.65   0.73\n",
      "who             0.64   0.6\n",
      "this            0.61   0.78\n",
      "to              0.61   0.66\n",
      "an              0.61   0.55\n",
      "story           0.6    0.98\n",
      "all             0.59   0.83\n",
      "it              0.58   0.5\n",
      "his             0.58   0.84\n",
      "in              0.58   0.61\n",
      "with            0.58   0.55\n",
      "into            0.57   0.56\n",
      "more            0.56   0.98\n",
      "the             0.56   0.53\n",
      "most            0.55   0.09\n",
      "be              0.55   0.7\n",
      "so              0.55   0.87\n",
      "a               0.54   0.02\n",
      "for             0.53   0.7\n",
      "that            0.53   0.52\n",
      "one             0.53   0.59\n",
      "movie           0.53   0.62\n",
      "of              0.53   0.51\n",
      "about           0.52   0.69\n",
      "by              0.49   0.54\n",
      "but             0.47   0.65\n",
      "as              0.47   0.68\n",
      "at              0.47   0.56\n",
      "`               0.46   0.6\n",
      "just            0.44   0.09\n",
      "on              0.44   0.62\n",
      "its             0.43   0.58\n",
      "out             0.42   0.1\n",
      "have            0.4    0.97\n",
      "than            0.34   0.02\n",
      "from            0.29   0.56\n",
      "if              0.24   0.14\n",
      "or              0.18   0.02\n",
      "too             0.04   0.05\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pairs)):\n",
    "    tab = []\n",
    "    for ele1, score1 in pairs[i]:\n",
    "        for ele2, score2 in pairs2[i]:\n",
    "            if ele1 == ele2:\n",
    "                tab.append((ele1, round(score1, 2),  round(score2, 2)))\n",
    "    print(tabulate(tab, headers=['word', 'normal', 'adv']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
