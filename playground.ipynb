{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0311 06:29:23.182612 140051521697600 file_utils.py:38] PyTorch version 1.4.0 available.\n",
      "I0311 06:29:24.844568 140051521697600 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "Loading faiss with AVX2 support.\n",
      "I0311 06:29:25.031044 140051521697600 modeling_bert.py:244] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = \"/disks/sdb/torch_home\"\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "from awesome_glue.task import *\n",
    "from awesome_glue.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for TOY-spacy.data exists\n",
      "*** load TOY-spacy.data from cache cost 4.42 seconds\n"
     ]
    }
   ],
   "source": [
    "toy_data = load_data('TOY', 'spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3801, 13419,  2493,     0,     0,     0],\n",
       "        [14825,     0,     0,     0,     0,     0],\n",
       "        [  862,   606, 16191, 13750,  9107,  5197],\n",
       "        [ 1357, 14668,  2489, 16219,  3719,  9718],\n",
       "        [ 3917, 11118, 14545,  5593,  4594,  2626]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = torch.rand(5, 6, 300)\n",
    "grads = torch.rand(5, 6, 300)\n",
    "embedding_matrix = torch.rand(30000, 300)\n",
    "src_tokens = torch.randint(vocab.get_vocab_size(), size=(5, 6))\n",
    "src_tokens[0, 3:]=0\n",
    "src_tokens[1, 1:]=0\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for TOY-spacy.data exists\n",
      "*** load TOY-spacy.data from cache cost 3.3 seconds\n"
     ]
    }
   ],
   "source": [
    "toy_data = load_data(\"TOY\", \"spacy\")\n",
    "vocab = toy_data['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@UNKNOWN@@'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_token_from_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlpx.interpret.attackers.cached_searcher import CachedWordSearcher, CachedIndexSearcher\n",
    "# searcher= CachedWordSearcher(\"nbrs.euc.top10.txt\")\n",
    "searcher= CachedIndexSearcher(\"nbrs.euc.top10.txt\", word2idx=vocab.get_token_index, idx2word=vocab.get_token_from_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.search(\"12131313\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_dot_grad.new_zeros(dir_dot_grad.size(), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5831e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.3415e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.9261e+07, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.6058e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 2.1660e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-5.3390e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[-1.3436e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.5468e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 3.5948e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-5.6091e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-2.2290e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.4018e-01, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[-8.9233e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-5.8944e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 3.5668e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.9396e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.9261e+07, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 2.9932e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[-6.6317e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-7.1371e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.9160e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.4855e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 3.0559e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 2.7708e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[ 3.1065e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-2.1343e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 6.6749e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.1743e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.4101e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.5731e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dir_dot_grad\n",
    "from luna import batch_pad\n",
    "\n",
    "searcher = CachedIndexSearcher(\"euc-topk-10.txt\",\n",
    "                                word2idx=vocab.get_token_index,\n",
    "                                idx2word=vocab.get_token_from_index)\n",
    "src_tokens_lst = src_tokens.tolist()\n",
    "idxes_to_mask = []\n",
    "for bid in range(src_tokens.size(0)):\n",
    "    for sid in range(src_tokens.size(1)):\n",
    "        if src_tokens[bid][sid] == 0:\n",
    "            idxes_to_mask.append([])\n",
    "            continue\n",
    "        _, idxs = searcher.search(src_tokens_lst[bid][sid])\n",
    "        idxes_to_mask.append(idxs)\n",
    "idxes_to_mask = src_tokens.new_tensor(batch_pad(idxes_to_mask, 0))\n",
    "idxes_to_mask = idxes_to_mask.view(*src_tokens.size(), -1)\n",
    "mask = scores.new_zeros(scores.size(), dtype=torch.bool)\n",
    "mask.scatter_(dim=2, \n",
    "              index=idxes_to_mask, \n",
    "              src=mask_idxes.new_ones(mask_idxes.size(), dtype=torch.bool))\n",
    "mask = ~mask\n",
    "dir_dot_grad.masked_fill(mask, -19260817)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_constraint(src_tokens, scores):\n",
    "    searcher = CachedIndexSearcher(\"nbrs.euc.top10.txt\",\n",
    "                                    word2idx=vocab.get_token_index,\n",
    "                                    idx2word=vocab.get_token_from_index)\n",
    "    mask = scores.new_zeros(scores.size(), dtype=torch.bool)\n",
    "    src_token_lst = src_tokens.tolist()\n",
    "    for bid in range(src_tokens.size(0)):\n",
    "        for sid in range(src_tokens.size(1)):\n",
    "            if src_tokens[bid][sid] == 0:\n",
    "                break\n",
    "            _, idxs = searcher.search(src_tokens_lst[bid][sid])\n",
    "            for idx in idxs:\n",
    "                mask[bid][sid][idx] = True\n",
    "    mask = ~mask\n",
    "    dir_dot_grad.masked_fill(mask, -19260817)\n",
    "    \n",
    "    \n",
    "def hotflip(src_tokens, embeds, grads, embedding_matrix, k=3, constraint=None):\n",
    "    k = min(k, src_tokens.size(1))\n",
    "    \n",
    "    # compute the direction vector dot the gradient \n",
    "    prev_embed_dot_grad = torch.einsum(\"bij,bij->bi\", grads, embeds)\n",
    "    new_embed_dot_grad = torch.einsum(\"bij,kj->bik\", grads, embedding_matrix)\n",
    "    dir_dot_grad = new_embed_dot_grad - prev_embed_dot_grad.unsqueeze(-1)\n",
    "    dir_dot_grad[src_tokens == 0] = -19260817.\n",
    "    \n",
    "    # maybe some constraints\n",
    "    if constraint == 'embed':\n",
    "        apply_constraint(src_tokens, dir_dot_grad)\n",
    "    \n",
    "    # select the top-k step\n",
    "    score_at_each_step, best_at_each_step = dir_dot_grad.max(2)\n",
    "    _, best_positions = score_at_each_step.topk(k)\n",
    "    \n",
    "    # use the selected token index to replace the original one \n",
    "    adv_tokens = src_tokens.clone()\n",
    "    src = best_at_each_step.gather(dim=1, index=best_positions)\n",
    "    adv_tokens.scatter_(dim=1, index=best_positions, src=src)\n",
    "    adv_tokens[src_tokens == 0] = 0\n",
    "    return adv_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9338,  1292,  1264,     0,     0,     0],\n",
       "        [23289,     0,     0,     0,     0,     0],\n",
       "        [  862,  1264, 16191,  1264,  1264,  5197],\n",
       "        [17234, 14668,  2489, 23289,  3719, 23300],\n",
       "        [ 3917, 18620, 14545,  4146, 19632,  2626]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotflip(src_tokens,  embeds, grads, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_index_select(inputs, indices):\n",
    "    # inputs are like B*T*D\n",
    "    # indices are like B*N\n",
    "    # return B*N*D\n",
    "    return torch.cat([torch.index_select(a, 0, i).unsqueeze(0) for a, i in zip(inputs, indices)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
