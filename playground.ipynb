{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = \"/disks/sdb/torch_home\"\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "from awesome_glue.task import *\n",
    "from awesome_glue.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for AGNEWS-spacy.data exists\n",
      "*** load AGNEWS-spacy.data from cache cost 18.8 seconds\n",
      "cache for AGNEWS-glove.vec exists\n",
      "*** load AGNEWS-glove.vec from cache cost 0.0567 seconds\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.task_id = 'AGNEWS'\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config\n",
    "\n",
    "values = list(task.vocab.get_index_to_token_vocabulary().values())\n",
    "results = []\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "for group in lazy_groups_of(values, 1024):\n",
    "    result = task.predictor.predict_batch_json([{\"sent\": ele} for ele in group])\n",
    "    result = [ele['probs'][0] for ele in result]\n",
    "    results.extend(result)\n",
    "pairs = sorted(zip(values, results), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for AGNEWS-spacy.data exists\n",
      "*** load AGNEWS-spacy.data from cache cost 17.6 seconds\n",
      "cache for AGNEWS-glove.vec exists\n",
      "*** load AGNEWS-glove.vec from cache cost 0.042 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f765871c10840a3b46e3e67bddba241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=47.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'accuracy': 0.8999332888592395, 'loss': 0.3075038285014477}\n"
     ]
    }
   ],
   "source": [
    "config._model_name = 'AGNEWS-lstm-hot.1.5.con'\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "task.model.eval()\n",
    "task.evaluate_model()\n",
    "config\n",
    "\n",
    "values = list(task.vocab.get_index_to_token_vocabulary().values())\n",
    "results = []\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "for group in lazy_groups_of(values, 1024):\n",
    "    result = task.predictor.predict_batch_json([{\"sent\": ele} for ele in group])\n",
    "    result = [ele['probs'][0] for ele in result]\n",
    "    results.extend(result)\n",
    "pairs2 = sorted(zip(values, results), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tickers 0.0 0.01\n",
      "Forbes.com 0.0 0.0\n",
      "peripherals 0.0 0.04\n",
      "camcorder 0.0 0.09\n",
      "fax 0.0 0.07\n",
      "lender 0.0 0.07\n",
      "KLM 0.0 0.01\n",
      "WMT.N 0.0 0.01\n",
      "lifecycle 0.0 0.01\n",
      "G20 0.0 0.01\n",
      "securities 0.0 0.08\n",
      "interface 0.0 0.02\n",
      "reinsurance 0.0 0.03\n",
      "quickinfo 0.0 0.0\n",
      "investing 0.0 0.05\n",
      "wireless 0.0 0.03\n",
      "router 0.0 0.03\n",
      "UAIR.O 0.0 0.01\n",
      "retirees 0.0 0.07\n",
      "generates 0.0 0.19\n",
      "www.investor.reuters.com 0.0 0.01\n",
      "55-a 0.0 0.01\n",
      "mortgage 0.0 0.05\n",
      "inflationary 0.0 0.03\n",
      "companys 0.0 0.02\n",
      "ConocoPhillips 0.0 0.01\n",
      "subscriptions 0.0 0.04\n",
      "bookkeeping 0.0 0.06\n",
      "spinner 0.0 0.08\n",
      "subsystem 0.0 0.01\n"
     ]
    }
   ],
   "source": [
    "for ele in pairs[:30]:\n",
    "    for ele2 in pairs2:\n",
    "        if ele[0] == ele2[0]:\n",
    "            print(ele[0], round(ele[1], 2), round(ele2[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tickers', 'Forbes.com', 'peripherals', 'camcorder', 'fax', 'lender', 'KLM', 'WMT.N', 'lifecycle', 'G20', 'securities', 'interface', 'reinsurance', 'quickinfo', 'investing', 'wireless', 'router', 'UAIR.O', 'retirees', 'generates', 'www.investor.reuters.com', '55-a', 'mortgage', 'inflationary', 'companys', 'ConocoPhillips', 'subscriptions', 'bookkeeping', 'spinner', 'subsystem']\n",
      "['HealthDay', 'swappers?', 'freeware', '700th', 'NEERGAARD', 'humphead', '8482', 'iPod', 'EMMA', 'LAURAN', \"Cash'n'Carrion\", 'RFID', 'Conservation', 'Unix', 'handhelds', 'Playstation', 'shareware', 'fourball', 'Gamers', 'Basketball', 'NHL', 'configurator', 'X-43A', 'Forrester', 'Jaschan', 'Shaquille', 'Email', 'Kobe', 'Vitali', 'aggregator']\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda x: x[0], pairs[:30])))\n",
    "print(list(map(lambda x: x[0], pairs2[:30])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for TOY-spacy.data exists\n",
      "*** load TOY-spacy.data from cache cost 4.25 seconds\n"
     ]
    }
   ],
   "source": [
    "toy_data = load_data(\"TOY\", \"spacy\")\n",
    "vocab = toy_data['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting /tmp/ENZYMES/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        print(dataset.num_node_features)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        print(x, x.size())\n",
    "        print(edge_index, edge_index.size())\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        print(x.size())\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0') torch.Size([2708, 1433])\n",
      "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]], device='cuda:0') torch.Size([2, 10556])\n",
      "torch.Size([2708, 16])\n",
      "torch.Size([2708])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    print(data.train_mask.size())\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(16, 32, 10, 100)\n",
    "\n",
    "rand = torch.randint(0, 10, (16, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 10, 100])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsz = rand.size()\n",
    "x.view(16 * 32, 10, 100).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
