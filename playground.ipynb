{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0331 03:25:43.913720 140479948564288 file_utils.py:38] PyTorch version 1.4.0 available.\n",
      "Loading faiss with AVX2 support.\n",
      "I0331 03:25:51.058516 140479948564288 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "I0331 03:25:51.064216 140479948564288 modeling_bert.py:244] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = \"/disks/sdb/torch_home\"\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "from awesome_glue.task import *\n",
    "from awesome_glue.config import Config\n",
    "from collections import defaultdict\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SNLI-spacy.data exists\n",
      "*** load SNLI-spacy.data from cache cost 50.4 seconds\n",
      "cache for SNLI-glove.vec exists\n",
      "*** load SNLI-glove.vec from cache cost 0.058 seconds\n",
      "Load model from saved/models/SNLI-esim/best.th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Basic Args:\n",
       "\t--task_id=SNLI\n",
       "\t--embed=\n",
       "\t--arch=esim\n",
       "\t--pretrain=glove\n",
       "\t--_model_name=\n",
       "\t--mode=attack\n",
       "\t--dir_temp=5.0\n",
       "\t--gnn_type=mean\n",
       "\t--gnn_hop=1\n",
       "\t--aug_data=\n",
       "\t--adv_iter=0\n",
       "\t--adv_policy=hot\n",
       "\t--adv_replace_num=5\n",
       "\t--adv_constraint=True\n",
       "\t--pred_ensemble=1\n",
       "\t--pred_transform=\n",
       "\t--pred_transform_args=\n",
       "\t--attack_method=pwws\n",
       "\t--attack_vectors=counter\n",
       "\t--attack_data_split=dev\n",
       "\t--attack_size=200\n",
       "\t--attack_gen_adv=False\n",
       "\t--adv_data=nogit/AGNEWS-lstm.hotflip.adv.tsv\n",
       "\t--alchemist=False\n",
       "\t--seed=2\n",
       "\t--cuda=3\n",
       "Deduced Args:\n",
       "\t--model_name=SNLI-esim\n",
       "\t--tokenizer=spacy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(2)\n",
    "\n",
    "config = Config()\n",
    "\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent1': 'A person on a horse jumps over a broken down airplane .',\n",
       " 'sent2': 'A person is outdoors , on a horse .'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField\n",
    "from allennlpx.allenutil import as_sentence\n",
    "allenutil.as_sentence(task.train_data[0].fields['sent1'])\n",
    "def as_json(instance: Instance):\n",
    "    ret = {}\n",
    "    for k, v in instance.items():\n",
    "        if isinstance(v, TextField):\n",
    "            ret[k] = as_sentence(v)\n",
    "    return ret\n",
    "as_json(task.train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'to',\n",
       " \"'s\",\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'it',\n",
       " 'as',\n",
       " 'with',\n",
       " 'an',\n",
       " 'film',\n",
       " 'for',\n",
       " 'its',\n",
       " 'movie',\n",
       " 'this',\n",
       " '`',\n",
       " 'you',\n",
       " 'be',\n",
       " 'but',\n",
       " 'on',\n",
       " 'by',\n",
       " 'more',\n",
       " 'one',\n",
       " '--',\n",
       " 'at',\n",
       " 'than',\n",
       " 'has',\n",
       " 'from',\n",
       " 'about',\n",
       " 'his',\n",
       " 'are',\n",
       " 'so',\n",
       " 'all',\n",
       " 'or',\n",
       " 'have',\n",
       " 'most',\n",
       " 'out',\n",
       " 'story',\n",
       " 'too',\n",
       " 'into',\n",
       " 'up',\n",
       " 'who',\n",
       " 'characters',\n",
       " 'i',\n",
       " 'comedy',\n",
       " 'if',\n",
       " 'just']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forbidden_words = DEFAULT_IGNORE_TOKENS\n",
    "forbidden_words.extend([\n",
    "    line.rstrip('\\n') for line in open(TASK_SPECS['SST']['banned_words'])\n",
    "])\n",
    "# forbidden_words += stopwords.words(\"english\")\n",
    "high_words = FreqUtil.topk_frequency(task.vocab, 50, 'most', forbidden_words)\n",
    "high_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-spacy.data exists\n",
      "*** load SST-spacy.data from cache cost 4.23 seconds\n",
      "cache for SST-glove.vec exists\n",
      "*** load SST-glove.vec from cache cost 0.0137 seconds\n",
      "Load model from saved/models/SST-lstm/best.th\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.task_id = 'SST'\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config\n",
    "\n",
    "\n",
    "# values = list(task.vocab.get_index_to_token_vocabulary().values())\n",
    "values = high_words\n",
    "results = defaultdict(lambda: [], {})\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "for group in lazy_groups_of(values, 1024):\n",
    "    result = task.predictor.predict_batch_json([{\"sent\": ele} for ele in group])\n",
    "    for i in range(len(result[0]['probs'])):\n",
    "        results[i].extend([ele['probs'][i] for ele in result])\n",
    "pairs = defaultdict(lambda: [], {})\n",
    "for i in range(len(results)):\n",
    "    pairs[i] = sorted(zip(values, results[i]), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for SST-spacy.data exists\n",
      "*** load SST-spacy.data from cache cost 3.22 seconds\n",
      "cache for SST-glove.vec exists\n",
      "*** load SST-glove.vec from cache cost 0.0091 seconds\n",
      "Load model from saved/models/SST-glstm/best.th\n"
     ]
    }
   ],
   "source": [
    "config._model_name = 'SST-glstm'\n",
    "task = Task(config)\n",
    "task.from_pretrained()\n",
    "config\n",
    "\n",
    "# values = list(task.vocab.get_index_to_token_vocabulary().values())\n",
    "values = high_words\n",
    "results = defaultdict(lambda: [], {})\n",
    "from allennlp.common.util import lazy_groups_of\n",
    "for group in lazy_groups_of(values, 1024):\n",
    "    result = task.predictor.predict_batch_json([{\"sent\": ele} for ele in group])\n",
    "    for i in range(len(result[0]['probs'])):\n",
    "        results[i].extend([ele['probs'][i] for ele in result])\n",
    "pairs2 = defaultdict(lambda: [], {})\n",
    "for i in range(len(results)):\n",
    "    pairs2[i] = sorted(zip(values, results[i]), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], []]\n",
      "[[1], [1]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "x=[]\n",
    "xs = [x] * 2\n",
    "ys = [deepcopy(ele) for ele in xs]\n",
    "ys[0].append(1)\n",
    "print(ys)\n",
    "ys = deepcopy(xs)\n",
    "ys[0].append(1)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'goto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-02e505c50643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgoto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I am trapped, please rescue!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'goto'"
     ]
    }
   ],
   "source": [
    "from goto import goto, label\n",
    "for i in range(9):\n",
    "    for j in range(9):\n",
    "        for k in range(9):\n",
    "            print(\"I am trapped, please rescue!\")\n",
    "            if k == 2:\n",
    "                goto .breakout # breaking out from a deeply nested loop\n",
    "label .breakout\n",
    "print(\"Freedom!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word          normal    adv\n",
      "----------  --------  -----\n",
      "too             0.96   0.95\n",
      "or              0.82   0.98\n",
      "if              0.76   0.86\n",
      "from            0.71   0.44\n",
      "than            0.66   0.98\n",
      "have            0.6    0.03\n",
      "out             0.58   0.9\n",
      "its             0.57   0.42\n",
      "on              0.56   0.38\n",
      "just            0.56   0.91\n",
      "`               0.54   0.4\n",
      "at              0.53   0.44\n",
      "as              0.53   0.32\n",
      "but             0.53   0.35\n",
      "by              0.51   0.46\n",
      "about           0.48   0.31\n",
      "of              0.47   0.49\n",
      "movie           0.47   0.38\n",
      "one             0.47   0.41\n",
      "that            0.47   0.48\n",
      "for             0.47   0.3\n",
      "a               0.46   0.98\n",
      "so              0.45   0.13\n",
      "be              0.45   0.3\n",
      "most            0.45   0.91\n",
      "the             0.44   0.47\n",
      "more            0.44   0.02\n",
      "into            0.43   0.44\n",
      "with            0.42   0.45\n",
      "in              0.42   0.39\n",
      "his             0.42   0.16\n",
      "it              0.42   0.5\n",
      "all             0.41   0.17\n",
      "story           0.4    0.02\n",
      "an              0.39   0.45\n",
      "to              0.39   0.34\n",
      "this            0.39   0.22\n",
      "who             0.36   0.4\n",
      "'s              0.35   0.27\n",
      "are             0.35   0.83\n",
      "--              0.35   0.51\n",
      "i               0.33   0.14\n",
      "up              0.33   0.14\n",
      "film            0.31   0.94\n",
      "and             0.28   0.99\n",
      "has             0.25   0.19\n",
      "is              0.23   0.03\n",
      "comedy          0.19   0.88\n",
      "characters      0.16   0.58\n",
      "you             0.07   0.01\n",
      "word          normal    adv\n",
      "----------  --------  -----\n",
      "you             0.93   0.99\n",
      "characters      0.84   0.42\n",
      "comedy          0.81   0.12\n",
      "is              0.77   0.97\n",
      "has             0.75   0.81\n",
      "and             0.72   0.01\n",
      "film            0.69   0.06\n",
      "up              0.67   0.86\n",
      "i               0.67   0.86\n",
      "--              0.65   0.49\n",
      "are             0.65   0.17\n",
      "'s              0.65   0.73\n",
      "who             0.64   0.6\n",
      "this            0.61   0.78\n",
      "to              0.61   0.66\n",
      "an              0.61   0.55\n",
      "story           0.6    0.98\n",
      "all             0.59   0.83\n",
      "it              0.58   0.5\n",
      "his             0.58   0.84\n",
      "in              0.58   0.61\n",
      "with            0.58   0.55\n",
      "into            0.57   0.56\n",
      "more            0.56   0.98\n",
      "the             0.56   0.53\n",
      "most            0.55   0.09\n",
      "be              0.55   0.7\n",
      "so              0.55   0.87\n",
      "a               0.54   0.02\n",
      "for             0.53   0.7\n",
      "that            0.53   0.52\n",
      "one             0.53   0.59\n",
      "movie           0.53   0.62\n",
      "of              0.53   0.51\n",
      "about           0.52   0.69\n",
      "by              0.49   0.54\n",
      "but             0.47   0.65\n",
      "as              0.47   0.68\n",
      "at              0.47   0.56\n",
      "`               0.46   0.6\n",
      "just            0.44   0.09\n",
      "on              0.44   0.62\n",
      "its             0.43   0.58\n",
      "out             0.42   0.1\n",
      "have            0.4    0.97\n",
      "than            0.34   0.02\n",
      "from            0.29   0.56\n",
      "if              0.24   0.14\n",
      "or              0.18   0.02\n",
      "too             0.04   0.05\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pairs)):\n",
    "    tab = []\n",
    "    for ele1, score1 in pairs[i]:\n",
    "        for ele2, score2 in pairs2[i]:\n",
    "            if ele1 == ele2:\n",
    "                tab.append((ele1, round(score1, 2),  round(score2, 2)))\n",
    "    print(tabulate(tab, headers=['word', 'normal', 'adv']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
