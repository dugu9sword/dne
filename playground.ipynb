{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0311 06:29:23.182612 140051521697600 file_utils.py:38] PyTorch version 1.4.0 available.\n",
      "I0311 06:29:24.844568 140051521697600 modeling.py:230] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "Loading faiss with AVX2 support.\n",
      "I0311 06:29:25.031044 140051521697600 modeling_bert.py:244] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_HOME'] = \"/disks/sdb/torch_home\"\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "from awesome_glue.task import *\n",
    "from awesome_glue.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "DAE HUB is running under fairseq  0.6.1\n",
      "| [src] dictionary: 49999 types\n",
      "| [tgt] dictionary: 49999 types\n",
      "| loading model(s) from /home/zhouyi/frequency/fsgec/out/models_pretrain/checkpoint9.pt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from awesome_glue.transforms import DAE, BackTrans\n",
    "dae = DAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk> c v g g h .\n",
      "c v g g h\n",
      "tensor([0, 0, 1, 2, 3, 4, 5, 5], dtype=torch.int32)\n",
      "<unk> w f ...\n",
      "hello b d e f\n",
      "tensor([1, 0, 2, 1, 3], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I am very happy .', 'Say hello b d e f .', 'c c v g g h .', 'b w f ...']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dae([\"i am very happy\", \"hello b d e f\", \"c v g g h\",'w yt f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for TOY-spacy.data exists\n",
      "*** load TOY-spacy.data from cache cost 4.42 seconds\n"
     ]
    }
   ],
   "source": [
    "toy_data = load_data('TOY', 'spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': {'tokens': {'tokens': tensor([2866,   60,  337,    3,   93, 2195,  585])}},\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.data.batch import Batch\n",
    "allennlp_collate([toy_data['data'][0][i] for i in range(2)])\n",
    "toy_data['data'][0][0].as_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3801, 13419,  2493,     0,     0,     0],\n",
       "        [14825,     0,     0,     0,     0,     0],\n",
       "        [  862,   606, 16191, 13750,  9107,  5197],\n",
       "        [ 1357, 14668,  2489, 16219,  3719,  9718],\n",
       "        [ 3917, 11118, 14545,  5593,  4594,  2626]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = torch.rand(5, 6, 300)\n",
    "grads = torch.rand(5, 6, 300)\n",
    "embedding_matrix = torch.rand(30000, 300)\n",
    "src_tokens = torch.randint(vocab.get_vocab_size(), size=(5, 6))\n",
    "src_tokens[0, 3:]=0\n",
    "src_tokens[1, 1:]=0\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache for TOY-spacy.data exists\n",
      "*** load TOY-spacy.data from cache cost 3.3 seconds\n"
     ]
    }
   ],
   "source": [
    "toy_data = load_data(\"TOY\", \"spacy\")\n",
    "vocab = toy_data['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@@UNKNOWN@@'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_token_from_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlpx.interpret.attackers.cached_searcher import CachedWordSearcher, CachedIndexSearcher\n",
    "# searcher= CachedWordSearcher(\"nbrs.euc.top10.txt\")\n",
    "searcher= CachedIndexSearcher(\"nbrs.euc.top10.txt\", word2idx=vocab.get_token_index, idx2word=vocab.get_token_from_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.search(\"12131313\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_dot_grad.new_zeros(dir_dot_grad.size(), dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5831e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.3415e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.9261e+07, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.6058e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 2.1660e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-5.3390e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[-1.3436e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.5468e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 3.5948e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-5.6091e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-2.2290e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.4018e-01, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[-8.9233e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-5.8944e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 3.5668e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.9396e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.9261e+07, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 2.9932e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[-6.6317e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-7.1371e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.9160e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.4855e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 3.0559e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 2.7708e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]],\n",
       "\n",
       "        [[ 3.1065e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-2.1343e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [ 6.6749e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-4.1743e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.4101e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07],\n",
       "         [-1.5731e+00, -1.9261e+07, -1.9261e+07,  ..., -1.9261e+07,\n",
       "          -1.9261e+07, -1.9261e+07]]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = dir_dot_grad\n",
    "from luna import batch_pad\n",
    "\n",
    "searcher = CachedIndexSearcher(\"euc-topk-10.txt\",\n",
    "                                word2idx=vocab.get_token_index,\n",
    "                                idx2word=vocab.get_token_from_index)\n",
    "src_tokens_lst = src_tokens.tolist()\n",
    "idxes_to_mask = []\n",
    "for bid in range(src_tokens.size(0)):\n",
    "    for sid in range(src_tokens.size(1)):\n",
    "        if src_tokens[bid][sid] == 0:\n",
    "            idxes_to_mask.append([])\n",
    "            continue\n",
    "        _, idxs = searcher.search(src_tokens_lst[bid][sid])\n",
    "        idxes_to_mask.append(idxs)\n",
    "idxes_to_mask = src_tokens.new_tensor(batch_pad(idxes_to_mask, 0))\n",
    "idxes_to_mask = idxes_to_mask.view(*src_tokens.size(), -1)\n",
    "mask = scores.new_zeros(scores.size(), dtype=torch.bool)\n",
    "mask.scatter_(dim=2, \n",
    "              index=idxes_to_mask, \n",
    "              src=mask_idxes.new_ones(mask_idxes.size(), dtype=torch.bool))\n",
    "mask = ~mask\n",
    "dir_dot_grad.masked_fill(mask, -19260817)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[2., 1., 4., 0., 4.],\n",
      "        [4., 4., 3., 3., 4.],\n",
      "        [2., 1., 3., 3., 1.],\n",
      "        [4., 0., 4., 3., 4.],\n",
      "        [3., 1., 4., 2., 3.],\n",
      "        [2., 0., 1., 4., 2.],\n",
      "        [1., 4., 4., 2., 2.]]),)\n",
      "tensor([[ 0.0423,  1.6962, -0.6991,  1.0964],\n",
      "        [ 0.9650,  2.1252, -0.9507,  2.1747],\n",
      "        [-0.7851,  0.2252,  0.4127,  1.1427],\n",
      "        [-0.8851,  0.7380,  0.1410,  1.7750],\n",
      "        [-0.2944,  1.0871,  0.0547,  1.2855],\n",
      "        [-1.5931, -0.4923, -0.2456,  1.8978],\n",
      "        [ 0.3658,  1.9037, -0.7813,  1.6545]], grad_fn=<AddmmBackward>)\n",
      "grad\n",
      "(tensor([7., 7., 7., 7.]), None, tensor([[18., 18., 18., 18.],\n",
      "        [11., 11., 11., 11.],\n",
      "        [23., 23., 23., 23.],\n",
      "        [17., 17., 17., 17.],\n",
      "        [20., 20., 20., 20.]]))\n",
      "(tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]),)\n"
     ]
    }
   ],
   "source": [
    "def bw_hook_layers(module, grad_in, grad_out):\n",
    "    print('grad')\n",
    "    print(grad_in)\n",
    "    print(grad_out)\n",
    "\n",
    "def fw_hook_layers(module, inputs, outputs):\n",
    "    print(inputs)\n",
    "    print(outputs)\n",
    "\n",
    "# linear = torch.nn.Embedding(5, 3)\n",
    "linear = torch.nn.Linear(5, 4)\n",
    "linear.register_backward_hook(bw_hook_layers)\n",
    "linear.register_forward_hook(fw_hook_layers)\n",
    "    \n",
    "linear(torch.randint(5, size=(7, 5)).float()).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_constraint(src_tokens, scores):\n",
    "    searcher = CachedIndexSearcher(\"nbrs.euc.top10.txt\",\n",
    "                                    word2idx=vocab.get_token_index,\n",
    "                                    idx2word=vocab.get_token_from_index)\n",
    "    mask = scores.new_zeros(scores.size(), dtype=torch.bool)\n",
    "    src_token_lst = src_tokens.tolist()\n",
    "    for bid in range(src_tokens.size(0)):\n",
    "        for sid in range(src_tokens.size(1)):\n",
    "            if src_tokens[bid][sid] == 0:\n",
    "                break\n",
    "            _, idxs = searcher.search(src_tokens_lst[bid][sid])\n",
    "            for idx in idxs:\n",
    "                mask[bid][sid][idx] = True\n",
    "    mask = ~mask\n",
    "    dir_dot_grad.masked_fill(mask, -19260817)\n",
    "    \n",
    "    \n",
    "def hotflip(src_tokens, embeds, grads, embedding_matrix, k=3, constraint=None):\n",
    "    k = min(k, src_tokens.size(1))\n",
    "    \n",
    "    # compute the direction vector dot the gradient \n",
    "    prev_embed_dot_grad = torch.einsum(\"bij,bij->bi\", grads, embeds)\n",
    "    new_embed_dot_grad = torch.einsum(\"bij,kj->bik\", grads, embedding_matrix)\n",
    "    dir_dot_grad = new_embed_dot_grad - prev_embed_dot_grad.unsqueeze(-1)\n",
    "    dir_dot_grad[src_tokens == 0] = -19260817.\n",
    "    \n",
    "    # maybe some constraints\n",
    "    if constraint == 'embed':\n",
    "        apply_constraint(src_tokens, dir_dot_grad)\n",
    "    \n",
    "    # select the top-k step\n",
    "    score_at_each_step, best_at_each_step = dir_dot_grad.max(2)\n",
    "    _, best_positions = score_at_each_step.topk(k)\n",
    "    \n",
    "    # use the selected token index to replace the original one \n",
    "    adv_tokens = src_tokens.clone()\n",
    "    src = best_at_each_step.gather(dim=1, index=best_positions)\n",
    "    adv_tokens.scatter_(dim=1, index=best_positions, src=src)\n",
    "    adv_tokens[src_tokens == 0] = 0\n",
    "    return adv_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9338,  1292,  1264,     0,     0,     0],\n",
       "        [23289,     0,     0,     0,     0,     0],\n",
       "        [  862,  1264, 16191,  1264,  1264,  5197],\n",
       "        [17234, 14668,  2489, 23289,  3719, 23300],\n",
       "        [ 3917, 18620, 14545,  4146, 19632,  2626]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotflip(src_tokens,  embeds, grads, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_index_select(inputs, indices):\n",
    "    # inputs are like B*T*D\n",
    "    # indices are like B*N\n",
    "    # return B*N*D\n",
    "    return torch.cat([torch.index_select(a, 0, i).unsqueeze(0) for a, i in zip(inputs, indices)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
